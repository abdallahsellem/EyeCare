{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1512919,"sourceType":"datasetVersion","datasetId":611716},{"sourceId":8063577,"sourceType":"datasetVersion","datasetId":4756927},{"sourceId":8201000,"sourceType":"datasetVersion","datasetId":4858313},{"sourceId":8220026,"sourceType":"datasetVersion","datasetId":4873013},{"sourceId":8278128,"sourceType":"datasetVersion","datasetId":4915803},{"sourceId":8285826,"sourceType":"datasetVersion","datasetId":4921257},{"sourceId":8740141,"sourceType":"datasetVersion","datasetId":5247380},{"sourceId":8740327,"sourceType":"datasetVersion","datasetId":5247522},{"sourceId":8740345,"sourceType":"datasetVersion","datasetId":5247537}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\npath = os.path.abspath(\"/kaggle/input/datatesting\")\nsys.path.append(path)\npath = os.path.abspath(\"/kaggle/input/ocular-disease-recognition-odir5k\")\n\nsys.path.append(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# get the current working directory\ncurrent_working_directory = os.getcwd()\n\n# print output to the console\nprint(current_working_directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Modules and Libraries \n","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport copy\nimport time\nimport argparse\nimport importlib\nimport numpy as np\nfrom torch.utils.data import DataLoader\nimport random\nfrom keras.metrics import Accuracy, F1Score,AUC\nfrom sklearn.metrics import roc_curve, auc, average_precision_score\nfrom torchvision import transforms\nimport torchvision\nfrom tensorflow.keras.metrics import AUC\nfrom torchvision.models import resnet50\nimport gc\nfrom  sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\nlabel2disease = ['N', 'D', 'G', 'C', 'A', 'H', 'M']\nimport os\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport numpy as np\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the Data ","metadata":{}},{"cell_type":"code","source":"csv_path = \"/kaggle/input/finaaaaaal-data/final_processed_modified_lastV_inShaaAllah.csv\"\nimages_folder=\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\"\ndf = pd.read_csv(csv_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing Some Labels \n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shuffle and Split the Data","metadata":{}},{"cell_type":"code","source":"df=df.sample(len(df),random_state=7)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df[df['O']!=1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_frequancy=[0,0,0,0,0,0,0,0]\nfor index, row in df.iterrows():\n    for i,diease in enumerate(label2disease):\n        if row[diease]==1:\n            labels_frequancy[i]+=1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_frequancy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filter data to get just required classes \n","metadata":{}},{"cell_type":"code","source":"others_class =df[df['target']==\"[0, 0, 0, 0, 0, 0, 0, 1]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(others_class.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hypertension_class =df[df['target']==\"[0, 0, 0, 0, 0, 1, 0, 0]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hypertension_class.sample(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glacouma_class =df[df['target']==\"[0, 0, 1, 0, 0, 0, 0, 0]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cataract_class =df[df['target']==\"[0, 0, 0, 1, 0, 0, 0, 0]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amd_class =df[df['target']==\"[0, 0, 0, 0, 1, 0, 0, 0]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetic_class =df[df['target']==\"[0, 1, 0, 0, 0, 0, 0, 0]\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(others_class.shape,hypertension_class.shape,glacouma_class.shape,amd_class.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes =pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes=pd.concat([aug_classes, hypertension_class], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes=pd.concat([aug_classes, glacouma_class], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes=pd.concat([aug_classes, amd_class], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\naug_classes=pd.concat([aug_classes, cataract_class], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\naug_classes=pd.concat([aug_classes, diabetic_class], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes=aug_classes.sample(len(aug_classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aug_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape[0]+aug_classes.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label2disease)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_frequancy=[0,0,0,0,0,0,0]\nfor index, row in df.iterrows():\n    for i,diease in enumerate(label2disease):\n        if row[diease]==1:\n            labels_frequancy[i]+=1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_frequancy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_rows = pd.merge(df, aug_classes, how='inner')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(common_rows)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[~df.apply(tuple, axis=1).isin(common_rows.apply(tuple, axis=1))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_rows = pd.merge(df, aug_classes, how='inner')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(common_rows)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = df[label2disease].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train , x_val , y_train, y_val = train_test_split(df[\"image\"],df[label2disease], test_size=0.2,random_state=9)\n\n# x_test , x_val , y_test, y_val = train_test_split(x_temp,y_temp, test_size=0.5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data= pd.concat([x_train, y_train], axis = 1) \n# test_data= pd.concat([x_test, y_test], axis = 1) \nval_data= pd.concat([x_val, y_val], axis = 1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape[0]+val_data.shape[0]+aug_classes.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_taining_frequancy=[0,0,0,0,0,0,0]\nfor index, row in train_data.iterrows():\n    for i,diease in enumerate(label2disease):\n        if row[diease]==1:\n            labels_taining_frequancy[i]+=1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(train_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_taining_frequancy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# balancing Validation Data by shuffiling and concatinating ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"conditions=[\"[0, 1, 0, 0, 0, 0, 0, 0]\",\"[0, 0, 1, 0, 0, 0, 0, 0]\",\"[0, 0, 0, 1, 0, 0, 0, 0]\",\"[0, 0, 0, 0, 1, 0, 0, 0]\",\"[0, 0, 0, 0, 0, 1, 0, 0]\"]\ndef balance_validation_data(train_df, val_df, label_columns):\n       # Copying rows that meet the condition to df2\n    for condition in conditions :\n        print(train_df.sample(5))\n        sampled_rows = train_df[train_df['target']==condition].sample(20)  # Change the sample size as needed\n        print(sampled_rows.shape)\n        val_df = pd.concat([val_df, sampled_rows], ignore_index=True)\n        # Removing the moved rows from df1\n        train_df = train_df.drop(sampled_rows.index)\n\n    return train_df, val_df\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_classes,val_data=balance_validation_data(aug_classes,val_data,label2disease)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_val_frequancy=[0,0,0,0,0,0,0]\nfor index, row in val_data.iterrows():\n    for i,diease in enumerate(label2disease):\n        if row[diease]==1:\n            labels_val_frequancy[i]+=1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aug_classes.shape,train_data.shape,val_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_taining_frequancy,labels_val_frequancy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_sample_weight\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_weights[0:10])\nprint(y_train[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the Images and Assign Labels ","metadata":{}},{"cell_type":"markdown","source":"### Apply Preprocessing ","metadata":{}},{"cell_type":"code","source":"from PIL import Image\ndef loadImg(path):\n\n    img = Image.open(path)\n    img = img.convert(\"RGB\")\n    img_array = np.array(img)\n    \n    return img_array\n\ndef cropImg(image , percentage = 0.8):\n    height, width, _ = image.shape\n    new_height = int(height * percentage)\n    new_width = int(width * percentage)\n\n    start_x = (width - new_width) // 2\n    start_y = (height - new_height) // 2\n\n    centered_region = image[start_y:start_y+new_height, start_x:start_x+new_width]\n    \n    return centered_region\n\ndef resizeImg(image, target_width=512, target_height =512):\n\n    original_height, original_width = image.shape[:2]\n    aspect_ratio = original_width / original_height\n    target_aspect_ratio = target_width / target_height\n\n    if aspect_ratio > target_aspect_ratio:\n        new_width = target_width\n        new_height = int(target_width / aspect_ratio)\n    else:\n        new_width = int(target_height * aspect_ratio)\n        new_height = target_height\n\n    resized_image = cv.resize(image, (new_width, new_height), interpolation=cv.INTER_CUBIC)\n    canvas = 255 * np.ones((target_height, target_width, 3), dtype=np.uint8)\n\n    x_offset = (target_width - new_width) // 2\n    y_offset = (target_height - new_height) // 2\n\n    canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_image\n\n    return canvas\n\ndef crop(image):\n\n    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n    blurred = cv.GaussianBlur(gray, (5, 5), 0)\n\n    # Detect circles using Hough Circle Transform\n    circles = cv.HoughCircles(blurred, cv.HOUGH_GRADIENT, dp=1, minDist=20,\n                               param1=50, param2=30, minRadius=0, maxRadius=0)\n\n    if circles is not None:\n        # Convert the (x, y) coordinates and radius of the circle to integers\n        circles = np.round(circles[0, :]).astype(\"int\")\n\n        # Assuming there's only one circle, extract its coordinates and radius\n        (x, y, r) = circles[0]\n\n        # Create a mask for the circle\n        mask = np.zeros_like(gray)\n        cv.circle(mask, (x, y), r, 255, thickness=-1)\n\n        # Crop the circle from the original image using the mask\n        masked_image = cv.bitwise_and(image, image, mask=mask)\n        contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n        max_contour = max(contours, key=cv.contourArea)\n        x, y, w, h = cv.boundingRect(max_contour)\n        cropped_image = masked_image[y:y+h, x:x+w]\n        resized_image = cv.resize(cropped_image,(224,224))\n        return resized_image , True\n\n\n    else:\n        print(\"No circles detected.\")\n        return image , False\n    \ndef rotate_image(image,angle):\n    # Get the image size\n    (height, width) = image.shape[:2]\n\n    # Define the center of the image\n    center = (width / 2, height / 2)\n    scale = 1.0\n    matrix = cv.getRotationMatrix2D(center, angle, scale)\n    rotated_by_matrix = cv.warpAffine(image, matrix, (width, height))\n    image_bgr=rotated_by_matrix\n    return image_bgr;\n\ndef gamma_correction(image):\n   # Gamma Correction\n    gamma = 1.2\n    lookup_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n    gamma_corrected_image = cv.LUT(image, lookup_table)\n    return gamma_corrected_image ;\n\n\ndef flip(image,direction=0):\n    image = cv.flip(image, direction) \n    return image \n\ndef fill(img, h, w):\n    img = cv.resize(img, (h, w), cv.INTER_CUBIC)\n    return img\n        \ndef horizontal_shift(img, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        print('Value should be less than 1 and greater than 0')\n        return img\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = w*ratio\n    if ratio > 0:\n        img = img[:, :int(w-to_shift), :]\n    if ratio < 0:\n        img = img[:, int(-1*to_shift):, :]\n    img = fill(img, h, w)\n    return img\n\n\ndef vertical_shift(img, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        print('Value should be less than 1 and greater than 0')\n        return img\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = h*ratio\n    if ratio > 0:\n        img = img[:int(h-to_shift), :, :]\n    if ratio < 0:\n        img = img[int(-1*to_shift):, :, :]\n    img = fill(img, h, w)\n    return img\n\n\ndef zoom(img, value):\n    if value > 1 or value < 0:\n        print('Value for zoom should be less than 1 and greater than 0')\n        return img\n    value = random.uniform(value, 1)\n    h, w = img.shape[:2]\n    h_taken = int(value*h)\n    w_taken = int(value*w)\n    h_start = random.randint(0, h-h_taken)\n    w_start = random.randint(0, w-w_taken)\n    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n    img = fill(img, h, w)\n    return img\n\ndef channel_shift(img, value):\n    value = int(random.uniform(-value, value))\n    img = img + value\n    img = np.clip(img, 0, 255)  # Clip values to stay within [0, 255]\n    img = img.astype(np.uint8)\n    return img\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def enhanceImg(img):\n    conv_img = cv.cvtColor(img,  cv.COLOR_RGB2YCrCb)\n    Y_channel = conv_img[: , : ,0]\n    Y_channel = Y_channel.astype(np.uint8)\n    \n    clahe = cv.createCLAHE(clipLimit=10.0, tileGridSize=(16,16))\n    cl = clahe.apply(Y_channel)\n    \n    merged = cv.merge((cl , conv_img[:,:,1], conv_img[:,:,2]))\n    modified_img = cv.cvtColor(merged , cv.COLOR_YCrCb2RGB)\n    \n    return modified_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imgs = df['iamge']\nrandom.seed(42)\nimage_size=224\ndef dataset_generator_aug(dff):\n    dataset = []\n    for index, row in dff.iterrows():\n        random.shuffle(dataset);\n        img_path = os.path.join(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\",row['image'])\n        try:\n            # Load image in color mode\n            image = loadImg(img_path)\n            image = resizeImg(image)\n            image,f = crop(image)\n\n            if f :\n                labels=[0,0,0,0,0,0,0]\n                for i,diease in enumerate(label2disease):\n                    if row[diease]==1:\n                        labels[i]=1 ;\n                dataset.append([np.array(enhanceImg(image)),np.array(labels)])\n            else:\n                  print(f\"Warning: Failed to crop image: {img_path}\")\n        except Exception as e:\n            print(f\"Error loading image: {img_path}: {e}\")\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=dataset_generator_aug(train_data)\n# test_data=dataset_generator_aug(test_data)\nval_data=dataset_generator_aug(val_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visulize the Images \n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(train_data)))\n    \n    image = train_data[sample][0]\n    print(image.shape)\n    category = train_data[sample][1]\n\n    plt.subplot(2,6,i+1)\n    plt.imshow(image)\nplt.tight_layout()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Augmentation on the data :\n","metadata":{}},{"cell_type":"code","source":"def dataset_generator_with_augmentation(dff):\n    dataset = []\n    for index, row in dff.iterrows():\n        random.shuffle(dataset);\n        img_path = os.path.join(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\",row['image'])\n        try:\n            # Load image in color mode\n            original_image = loadImg(img_path)\n            original_image = resizeImg(original_image)\n            original_image,f = crop(original_image)\n            image=enhanceImg(original_image) \n            if f :\n                labels=[0,0,0,0,0,0,0]\n                for i,diease in enumerate(label2disease):\n                    if row[diease]==1:\n                        labels[i]=1 ;\n                        # 5 5 7 12 6\n                        \n                        \n                if labels[1]==1:\n                    dataset.append([np.array(channel_shift(image,int(random.uniform(10, 20)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 150)))),np.array(labels)])\n                    dataset.append([np.array(vertical_shift(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(original_image),np.array(labels)])\n                if(labels[3]==1):\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 120)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(vertical_shift(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1, .2))),np.array(labels)])\n\n                if(labels[2]==1):\n                    dataset.append([np.array(channel_shift(image,int(random.uniform(10, 20)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 120)))),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1, .2))),np.array(labels)])\n                if labels[4]==1:\n                    dataset.append([np.array(channel_shift(image,int(random.uniform(10, 20)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 150)))),np.array(labels)])\n                    dataset.append([np.array(vertical_shift(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(original_image),np.array(labels)])\n                if labels[5]==1:\n                    dataset.append([np.array(channel_shift(image,int(random.uniform(10, 20)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 150)))),np.array(labels)])\n                    dataset.append([np.array(vertical_shift(image,random.uniform(.1,.3))),np.array(labels)])\n                    dataset.append([np.array(horizontal_shift(image,random.uniform(0, .3))),np.array(labels)])\n                    dataset.append([np.array(gamma_correction(image)),np.array(labels)])\n                    dataset.append([np.array(original_image),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1,.25))),np.array(labels)])\n                if labels[6]==1:\n                    dataset.append([np.array(channel_shift(image,int(random.uniform(10, 20)))),np.array(labels)])\n                    dataset.append([np.array(flip(image,1)),np.array(labels)])\n                    dataset.append([np.array(rotate_image(image,int(random.uniform(30, 150)))),np.array(labels)])\n                    dataset.append([np.array(vertical_shift(image,random.uniform(.1,.3))),np.array(labels)])\n                    dataset.append([np.array(horizontal_shift(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(gamma_correction(image)),np.array(labels)])\n                    dataset.append([np.array(original_image),np.array(labels)])\n                    \n                if labels[7]==1:\n                    dataset.append([np.array(horizontal_shift(image,random.uniform(.1, .3))),np.array(labels)])\n                    dataset.append([np.array(gamma_correction(image)),np.array(labels)])\n                    dataset.append([np.array(original_image),np.array(labels)])\n                    dataset.append([np.array(zoom(image,random.uniform(.1,.25))),np.array(labels)])\n\n            else:\n                  print(f\"Warning: Failed to crop image: {img_path}\")\n        except Exception as e:\n            print(f\"Error loading image: {img_path}: {e}\")\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmanted_data=dataset_generator_with_augmentation(aug_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(augmanted_data),len(train_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in augmanted_data:\n    train_data.append(item)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.shuffle(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Data \n","metadata":{}},{"cell_type":"code","source":"#Divide the dataset into 2 predictors and target...\n#here predictors would be the image and target would be the label\nfrom tensorflow.keras.utils import to_categorical\n\ntrain_x = np.array([i[0]/255.0 for i in train_data]).reshape(-1,image_size,image_size,3).astype(np.float32);\ntrain_y = np.array([i[1]/1.0 for i in train_data]).astype(np.float32);\n\n# test_x = np.array([i[0]/255.0 for i in test_data]).reshape(-1,image_size,image_size,3).astype(np.float32);\n# test_y = np.array([i[1] for i in test_data])\n\nval_x = np.array([i[0]/255.0 for i in val_data]).reshape(-1,image_size,image_size,3).astype(np.float32);\nval_y = np.array([i[1]/1.0 for i in val_data]).astype(np.float32);\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visulize after Loaded \n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(train_x)))\n    \n    image = train_x[sample]\n    print(image.shape)\n    plt.subplot(2,6,i+1)\n    plt.imshow(image)\nplt.tight_layout()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(train_x)))\n    \n    image = train_x[sample]\n    print(image.shape)\n    plt.subplot(2,6,i+1)\n    plt.imshow(image)\nplt.tight_layout()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = os.path.join(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\",\"968_left.jpg\")\n\n# Load image in color mode\noriginal_image = loadImg(img_path)\noriginal_image = resizeImg(original_image)\noriginal_image,f = crop(original_image)\nimage1=enhanceImg(original_image) \nimage2=channel_shift(image1,40)\n\nplt.figure(figsize=(12,7))\nplt.subplot(1,2,1)\nplt.imshow(image1)\n\nplt.subplot(1,2,2)\n\nplt.imshow(image2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Layers and Libraries ","metadata":{}},{"cell_type":"code","source":"print(train_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_map={}\nfor image in train_y:\n    if str(image) in freq_map:\n        freq_map[str(image)]+=1 \n    else:\n        freq_map[str(image)]=1 \nprint(freq_map)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_map={}\nfor image in val_y:\n    if str(image) in freq_map:\n        freq_map[str(image)]+=1 \n    else:\n        freq_map[str(image)]=1 \nprint(freq_map)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_val_frequancy=[0,0,0,0,0,0,0]\nfor image in train_y:\n    for i,dieases in enumerate(image) :\n            if(dieases==1):\n                labels_val_frequancy[i]+=1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels_val_frequancy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate,Average,BatchNormalization,Dropout,Add,Multiply\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,AdamW\nfrom keras.losses import CategoricalCrossentropy,BinaryCrossentropy,BinaryFocalCrossentropy\nfrom keras.optimizers import Adam\nfrom keras.initializers import LecunUniform\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D\nfrom tensorflow.keras.applications import ConvNeXtBase ,EfficientNetB3,InceptionResNetV2,VGG19\nimport torch.nn.functional as F\nfrom keras.regularizers import l2\nfrom keras_cv.layers import ChannelShuffle\nfrom keras import activations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DckNetLayer(x):\n    num_filters = x.shape[-1]\n    branch1 = Sequential()\n    branch1.add(Conv2D(filters=num_filters, kernel_size=(2, 2), padding='same',\n                                            activation='relu', dilation_rate=4,kernel_initializer=\"he_normal\"))\n    branch1.add(BatchNormalization())\n\n    \n    \n    \n    branch2 = Sequential()\n    branch2.add(Conv2D(filters=num_filters, kernel_size=(2, 2), padding='same',\n                                            activation='relu', dilation_rate=3,kernel_initializer=\"he_normal\"))\n    branch2.add(BatchNormalization())\n\n    \n    \n    \n    \n    branch3 = Sequential()\n    branch3.add(Conv2D(filters=num_filters, kernel_size=(2, 2), padding='same',\n                                            activation='relu', dilation_rate=2,kernel_initializer=\"he_normal\"))\n    branch3.add(BatchNormalization())\n    \n    \n    P3=branch1(x)\n    P2=branch2(x)\n    P1=branch3(x)\n    \n    \n    MergedBranch1=Add()([P3, P2, P1])\n    \n    GMP=GlobalMaxPooling2D()(MergedBranch1)\n    GAP=GlobalAveragePooling2D()(MergedBranch1)\n    MergedBranch2=Add()([GMP, GAP])\n    Q_dash=Dropout(0.5)(MergedBranch2)\n    FC_layer = Sequential()\n    FC_layer.add(Dense(num_filters, activation='relu',kernel_initializer=\"he_normal\"))\n    FC_layer.add(Dense(num_filters, activation='sigmoid',kernel_initializer=\"he_normal\"))\n    R=FC_layer(Q_dash)\n    \n    S3= Multiply()([P3,R])\n    S2= Multiply()([P2,R])\n    S1= Multiply()([P1,R])\n    \n    MergedBranch3=Add()([S3, S2, S1])\n    \n    output=MergedBranch3\n    return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SqueezeAndExcuetionLayer(x):\n    num_filters = x.shape[-1]\n    GAP1=GlobalAveragePooling2D()(x)\n    FC_layer = Sequential()\n    FC_layer.add(Dense(num_filters, activation='relu',kernel_initializer=\"he_normal\"))\n    FC_layer.add(Dense(num_filters, activation='sigmoid',kernel_initializer=\"he_normal\"))\n    FC1_output=FC_layer(GAP1)\n    SAQ_output= Multiply()([FC1_output,x])\n    return SAQ_output\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_y.dtype)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nmodel_pre1 = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_shape=(image_size,image_size,3))\nmodel_pre1.trainable=False ;\n\nfor layer in model_pre1.layers[:20]:\n    print(layer.trainable)     \n# Define the model creation function\ndef create_multimodal_model(image_size, l2_reg=0.001):\n    img1_input = Input(shape=(image_size, image_size, 3))\n    features = model_pre1(img1_input)\n    print(features)\n    features_shape=features.shape[-1]\n    x=ChannelShuffle(groups=3,seed=17)(features)\n    x=DckNetLayer(x)\n    x=SqueezeAndExcuetionLayer(x)\n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dense(1024,kernel_initializer=\"he_normal\")(x)\n    x=activations.relu(x)\n    x=Dropout(.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(1024,kernel_initializer=\"he_normal\")(x)\n    x=activations.relu(x)\n    x=Dropout(.35)(x)\n    x = BatchNormalization()(x)\n    x = Dense(7,kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.01))(x)\n    x=activations.sigmoid(x)\n    output = x\n\n    return Model(inputs=img1_input, outputs=output)\n\n# Compile the model\nmodel = create_multimodal_model(224)\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# model_pre1 = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_shape=(image_size,image_size,3))\n# model_pre1.trainable=False ;\n\n# for layer in model_pre1.layers[:20]:\n#     print(layer.trainable)     \n# # Define the model creation function\n# def create_multimodal_model(image_size, l2_reg=0.001):\n#     img1_input = Input(shape=(image_size, image_size, 3))\n#     features = model_pre1(img1_input)\n#     shuffled=ChannelShuffle(groups=3,seed=42)(features)\n#     x=DckNetLayer(shuffled)\n#     x=SqueezeAndExcuetionLayer(x)\n#     x = GlobalAveragePooling2D()(x)\n#     x = Dropout(0.5)(x)\n#     x = Dense(256, activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dense(8, activation='sigmoid')(x)    \n#     output = x\n\n#     return Model(inputs=img1_input, outputs=output)\n\n# # Compile the model\n# model = create_multimodal_model(224)\n# model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.layers[1].trainable)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nlr_schedule=0.0005\n\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\",\"f1_score\",\"auc\"])\n\nes_callback = EarlyStopping(patience=30,monitor='val_accuracy',mode='max', verbose=1,restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=7, verbose=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_x.shape,train_y.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_weights = compute_sample_weight(class_weight='balanced', y=train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\",AUC()])\n# class_weights={2: 0.3,4:0.8,5:0.8,7:0.3}\n# history =model.fit(train_x, train_y, \n#           validation_data=(val_x, val_y),\n#           epochs=55,callbacks=[es_callback, reduce_lr], batch_size=32,class_weight=class_weights)\nhistory =model.fit(train_x, train_y, \n          validation_data=(val_x, val_y),\n          epochs=50,callbacks=[es_callback, reduce_lr], batch_size=32,sample_weight=sample_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.trainable = True\ninception_resnet_v2_block = None\nsequintail=[]\nfor layer in model.layers:\n    if layer.name[0:-1]==\"batch_normalization\":\n        layer.trainable=False\n    else:\n        layer.trainable=True\n        \n    if layer.name == 'inception_resnet_v2':\n        inception_resnet_v2_block = layer\n    if(layer.name[0:10]==\"sequential\"):\n        sequintail.append(layer)\n\n\nfor layer in inception_resnet_v2_block.layers:\n    if isinstance(layer, BatchNormalization):\n        layer.trainable=False\n        \n        \n# for seq in sequintail:\n#     for layer in seq.layers :\n#         if layer.name[0:19]==\"batch_normalization\":\n#             layer.trainable=False\n#         else:\n#             layer.trainable=True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nlr_schedule=.01\n\nmodel.compile(optimizer=Adam(0.00005), loss=\"binary_crossentropy\", metrics=[\"accuracy\",\"f1_score\",\"auc\"])\n\nes_callback = EarlyStopping(patience=10,monitor='val_accuracy',mode='max',verbose=1,restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\",AUC()])\nprint(train_x.shape,train_y.shape)\n\nhistory =model.fit(train_x, train_y, \n          validation_data=(val_x, val_y),\n          epochs=100,callbacks=[es_callback, reduce_lr], batch_size=16,shuffle=True,sample_weight=sample_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss,accuracy,f1score,auc = model.evaluate(val_x,val_y)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\npredict_y=model.predict(val_x)\nbinary_predictions = (predict_y >= 0.5).astype(int)\nprint(classification_report(val_y, binary_predictions, target_names=label2disease))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"without_other_90%PrectModel.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.saving import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2= load_model(\"/kaggle/working/without_other_90%PrectModel.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport google.auth\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\nfrom googleapiclient.http import MediaFileUpload\nfrom google.auth.transport.requests import Request\n\nfrom google_auth_oauthlib.flow import InstalledAppFlow\n\nfrom google.oauth2.credentials import Credentials\n\n\nSCOPES = [\"https://www.googleapis.com/auth/drive\"]\n\ndef upload_basic(filename,token_path):\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists(token_path):\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                \"cred.json\", SCOPES\n            )\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open(token_path, \"w\") as token:\n            token.write(creds.to_json())\n\n    try:\n        # create drive api client\n        service = build(\"drive\", \"v3\", credentials=creds)\n\n        file_metadata = {\"name\": f\"{filename}\"}\n        media = MediaFileUpload(f\"{filename}\")\n        # pylint: disable=maybe-no-member\n        file = (\n            service.files()\n            .create(body=file_metadata, media_body=media, fields=\"id\")\n            .execute()\n        )\n        print(f'File ID: {file.get(\"id\")}')\n\n    except HttpError as error:\n        print(f\"An error occurred: {error}\")\n        file = None\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upload_basic(\"/kaggle/working/without_other_90%PrectModel.keras\",\"/kaggle/input/a5eermara/token.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_other=[]\nfor index, row in others_class.iterrows():\n        img_path = os.path.join(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\",row['image'])\n        try:\n            # Load image in color mode\n            image = loadImg(img_path)\n            image = resizeImg(image)\n            image,f = crop(image)\n            image=enhanceImg(original_image) \n\n            labels=[0,0,0,0,0,0,0]\n            for i,diease in enumerate(label2disease):\n                if row[diease]==1:\n                    labels[i]=1 ;        \n            test_other.append([np.array(image),np.array(labels)])\n        except Exception as Ex :\n            print(Ex)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_result_x = np.array([i[0]/255.0 for i in test_other]).reshape(-1,image_size,image_size,3).astype(np.float32);\ntest_result_y = np.array([i[1]/1.0 for i in test_other]).astype(np.float32);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\npredict_y=model.predict(test_result_x)\nbinary_predictions = (predict_y >= 0.35).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(binary_predictions[0:2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwrongs=0 \nfor pred in binary_predictions:\n    if (predastype(int) == [0,0,0,0,0,0,0]).all() :\n        wrongs+=1 ;\nprint(wrongs)\nprint(wrongs/len(binary_predictions*1.0))\n# print(classification_report(test_result_y, binary_predictions, target_names=label2disease))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}